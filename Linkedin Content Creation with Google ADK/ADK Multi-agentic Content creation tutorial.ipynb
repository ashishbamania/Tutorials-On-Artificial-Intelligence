{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6EwugA6qwBR"
      },
      "outputs": [],
      "source": [
        "!uv pip install google-adk --prerelease=allow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set Google AI Studio API key\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get(\"GOOGLE_API_KEY\")"
      ],
      "metadata": {
        "id": "ldemphfus7eZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set constants\n",
        "GEMINI_MODEL = \"gemini-2.0-flash\"\n",
        "APP_NAME = \"linkedin_content_creation_app\"\n",
        "USER_ID = \"ashish_bamania\"\n",
        "SESSION_ID = \"content_session_01\""
      ],
      "metadata": {
        "id": "K4FBGJXttXbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.adk.agents.llm_agent import LlmAgent\n",
        "from google.adk.tools import google_search\n",
        "\n",
        "# Google Research Agent\n",
        "google_research_agent = LlmAgent(\n",
        "    name = \"Google_Research_Agent\",\n",
        "    model = GEMINI_MODEL,\n",
        "    instruction = \"\"\"\n",
        "    You are a Research AI agent.\n",
        "    Use Google search to find recent and relevant information on the provided topic.\n",
        "    **Do not** add information on your own apart from what you found after the Google search.\n",
        "    Summarize key points, statistics, and insights in bullet points.\n",
        "    \"\"\",\n",
        "    description = \"Researches on a given topic using Google Search.\",\n",
        "    tools = [google_search],\n",
        "    output_key = \"google_research_summary\"\n",
        ")"
      ],
      "metadata": {
        "id": "NueyzPJLrTo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!uv pip install -qU duckduckgo-search langchain-community --prerelease=allow"
      ],
      "metadata": {
        "id": "5shI7aIctylh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up Duckduckgo search tool from Langchain\n",
        "\n",
        "from google.adk.tools.langchain_tool import LangchainTool\n",
        "from langchain_community.tools import DuckDuckGoSearchRun\n",
        "\n",
        "# Instantiate the tool\n",
        "duckduckgo_tool_instance = DuckDuckGoSearchRun(\n",
        "    max_results = 5,\n",
        ")\n",
        "\n",
        "# Wrap the tool in the LangchainTool class from ADK\n",
        "adk_duckduckgo_tool = LangchainTool(\n",
        "    tool=duckduckgo_tool_instance,\n",
        ")"
      ],
      "metadata": {
        "id": "lwkJG9CLttf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DuckDuckGo Research Agent\n",
        "duckduckgo_research_agent = LlmAgent(\n",
        "    name = \"DuckDuckGo_Research_Agent\",\n",
        "    model = GEMINI_MODEL,\n",
        "    instruction = \"\"\"\n",
        "    You are a Research AI agent.\n",
        "    Use DuckDuckGo search to find recent and relevant information on the provided topic.\n",
        "    **Do not** add information on your own apart from what you found after the DuckDuckGo search.\n",
        "    Summarize key points, statistics, and insights in bullet points.\n",
        "    \"\"\",\n",
        "    description = \"Researches on a given topic using DuckDuckGo Search.\",\n",
        "    tools = [adk_duckduckgo_tool],\n",
        "    output_key = \"duckduckgo_research_summary\"\n",
        ")"
      ],
      "metadata": {
        "id": "YnNdADkDsGl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.adk.agents.parallel_agent import ParallelAgent\n",
        "\n",
        "# Parallel Web Research Agent\n",
        "parallel_web_research_agent = ParallelAgent(\n",
        "    name = \"Parallel_Web_Research_Agent\",\n",
        "    sub_agents = [google_research_agent, duckduckgo_research_agent]\n",
        ")"
      ],
      "metadata": {
        "id": "A6fkUAg2uroN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge Research Agent (combine Google and DuckDuckGo results)\n",
        "merge_research_agent = LlmAgent(\n",
        "    name = \"Merge_Research_Agent\",\n",
        "    model = GEMINI_MODEL,\n",
        "    instruction = \"\"\"\n",
        "    You are a Content Merging AI.\n",
        "    Merge the outputs provided by the Google and DuckDuckGo agents in the session state under the keys 'google_research_summary' and 'duckduckgo_research_summary', respectively.\n",
        "    **Do not** add information on your own.\n",
        "    Remove duplicates.\n",
        "    Summarize key points clearly in bullet points.\n",
        "    \"\"\",\n",
        "    description = \"Merges research results from Google and DuckDuckGo.\",\n",
        "    output_key = \"merged_research_summary\"\n",
        ")"
      ],
      "metadata": {
        "id": "KB5EL7d9w3L3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Writer Agent\n",
        "writer_agent = LlmAgent(\n",
        "    name = \"Writer_Agent\",\n",
        "    model = GEMINI_MODEL,\n",
        "    instruction = \"\"\"\n",
        "    You are a LinkedIn Content Writer AI.\n",
        "    Based on the research summary provided in session state with the key 'merged_research_summary', draft a LinkedIn post that includes:\n",
        "    - A compelling hook and heading\n",
        "    - Key insights (describing the topic in technical detail if available)\n",
        "    - A clear call-to-action\n",
        "\n",
        "    Ensure the tone is professional and engaging.\n",
        "    **Do not**  add links to any external resources.\n",
        "    **Do not**  add your own information and your writing should be totally based on the research summary.\n",
        "    \"\"\",\n",
        "    description = \"Drafts initial LinkedIn post based on research results.\",\n",
        "    output_key = \"initial_draft\"\n",
        ")"
      ],
      "metadata": {
        "id": "Q4PKTyMaxnBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SEO Optimizer Agent\n",
        "seo_optimizer_agent = LlmAgent(\n",
        "    name = \"SEO_Optimizer_Agent\",\n",
        "    model = GEMINI_MODEL,\n",
        "    instruction = \"\"\"\n",
        "    You are an SEO Optimizer AI.\n",
        "    Enhance the draft provided in session state with the key 'initial_draft' by:\n",
        "    - Incorporating relevant keywords\n",
        "    - Adding appropriate hashtags (**only** 3)\n",
        "    - Ensuring optimal length (not omiting relevant research details) and readability\n",
        "    - Formatting for LinkedIn best practices\n",
        "    \"\"\",\n",
        "    description=\"Optimizes content for SEO and LinkedIn formatting.\",\n",
        "    output_key=\"seo_optimized_draft\"\n",
        ")"
      ],
      "metadata": {
        "id": "7541sFRxxpg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final draft guardrail\n",
        "\n",
        "import re\n",
        "import copy\n",
        "from typing import Optional\n",
        "from google.adk.agents.callback_context import CallbackContext\n",
        "from google.adk.models import LlmResponse\n",
        "from google.genai import types\n",
        "\n",
        "def final_draft_guardrail(callback_context: CallbackContext, llm_response: LlmResponse) -> Optional[LlmResponse]:\n",
        "    agent_name = callback_context.agent_name\n",
        "\n",
        "    print(f\"[Callback] Running guardrail for: {agent_name}\")\n",
        "\n",
        "    if not llm_response.content or not llm_response.content.parts:\n",
        "        print(\"[Callback] No content found in LLM response.\")\n",
        "        return None\n",
        "\n",
        "    part = llm_response.content.parts[0]\n",
        "\n",
        "    if part.function_call or not part.text:\n",
        "        print(\"[Callback] Skipping guardrail because response contains function call or no text.\")\n",
        "        return None\n",
        "\n",
        "    original_text = part.text\n",
        "    text = original_text\n",
        "    modified = False\n",
        "\n",
        "    # Remove markdown links like [text](url)\n",
        "    new_text = re.sub(r'\\[.*?\\]\\(.*?\\)', '', text)\n",
        "\n",
        "    if new_text != text:\n",
        "        print(\"[Callback] Markdown links removed.\")\n",
        "        text = new_text\n",
        "        modified = True\n",
        "\n",
        "    # Remove raw URLs\n",
        "    new_text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
        "\n",
        "    if new_text != text:\n",
        "        print(\"[Callback] Raw URLs removed.\")\n",
        "        text = new_text\n",
        "        modified = True\n",
        "\n",
        "    # Remove markdown formatting\n",
        "    text_no_md = re.sub(r'\\*\\*(.*?)\\*\\*', r'\\1', text)\n",
        "    text_no_md = re.sub(r'__(.*?)__', r'\\1', text_no_md)\n",
        "    text_no_md = re.sub(r'\\*(.*?)\\*', r'\\1', text_no_md)\n",
        "    text_no_md = re.sub(r'_(.*?)_', r'\\1', text_no_md)\n",
        "\n",
        "    if text_no_md != text:\n",
        "        print(\"[Callback] Markdown formatting removed.\")\n",
        "        text = text_no_md\n",
        "        modified = True\n",
        "\n",
        "    # Remove leftover [ ] brackets\n",
        "    if '[' in text or ']' in text:\n",
        "        text = text.replace('[', '').replace(']', '')\n",
        "        print(\"[Callback] Square brackets removed.\")\n",
        "        modified = True\n",
        "\n",
        "    # Replace markdown bullets with dashes\n",
        "    bullet_converted = re.sub(r'^\\s*\\*\\s+', '- ', text, flags=re.MULTILINE)\n",
        "\n",
        "    if bullet_converted != text:\n",
        "        print(\"[Callback] Markdown bullet points replaced with dashes.\")\n",
        "        text = bullet_converted\n",
        "        modified = True\n",
        "\n",
        "    # Remove intro phrases\n",
        "    intro_patterns = [\n",
        "        r'^\\s*Here is.*?:\\s*',\n",
        "        r'^\\s*Final draft.*?:\\s*',\n",
        "        r'^\\s*Here\\'s.*?:\\s*',\n",
        "        r'^\\s*Your post.*?:\\s*'\n",
        "    ]\n",
        "\n",
        "    for pattern in intro_patterns:\n",
        "        new_text = re.sub(pattern, '', text, flags=re.IGNORECASE)\n",
        "\n",
        "        if new_text != text:\n",
        "            print(f\"[Callback] Intro phrase removed using pattern: {pattern}\")\n",
        "            text = new_text\n",
        "            modified = True\n",
        "\n",
        "    # Extract hashtags\n",
        "    hashtags = re.findall(r\"#\\w+\", text)\n",
        "\n",
        "    if hashtags:\n",
        "        print(f\"[Callback] Extracted hashtags: {hashtags}\")\n",
        "        modified = True\n",
        "\n",
        "    if len(hashtags) > 3:\n",
        "        print(f\"[Callback] More than 3 hashtags found. Trimming to: {hashtags[:3]}\")\n",
        "        hashtags = hashtags[:3]\n",
        "\n",
        "    hashtags = [tag.lower() for tag in hashtags]\n",
        "\n",
        "    # Remove hashtags from main text\n",
        "    cleaned_text = re.sub(r\"#\\S+\", \"\", text)\n",
        "\n",
        "    if cleaned_text != text:\n",
        "        print(\"[Callback] Hashtags removed from main text.\")\n",
        "        text = cleaned_text\n",
        "        modified = True\n",
        "\n",
        "    if not modified:\n",
        "        print(\"[Callback] No modifications made to the response text.\")\n",
        "        return None\n",
        "\n",
        "    # Create final text\n",
        "    final_text = (\n",
        "        f\"{text.strip()}\\n\\n\"\n",
        "        f\"💡 Like this perspective? Follow Dr. Ashish Bamania to stay connected: https://www.linkedin.com/in/ashishbamania \"\n",
        "        f\"{' '.join(hashtags)}\"\n",
        "    )\n",
        "\n",
        "    print(\"[Callback] Final CTA and hashtags added.\")\n",
        "\n",
        "    modified_parts = [copy.deepcopy(part)]\n",
        "    modified_parts[0].text = final_text.strip()\n",
        "\n",
        "    new_response = LlmResponse(\n",
        "        content=types.Content(role=\"model\", parts=modified_parts),\n",
        "        grounding_metadata=llm_response.grounding_metadata\n",
        "    )\n",
        "\n",
        "    print(\"[Callback] Guardrail applied successfully. Modified text returned.\")\n",
        "\n",
        "    return new_response"
      ],
      "metadata": {
        "id": "MPE_zNzMyTup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_draft_writing_agent = LlmAgent(\n",
        "    name = \"Final_Draft_Writing_Agent\",\n",
        "    model = GEMINI_MODEL,\n",
        "    instruction = \"\"\"\n",
        "    You are a LinkedIn Post Drafting AI.\n",
        "    Review the optimized content provided in the session state with the key 'seo_optimized_draft' for:\n",
        "    - Clarity and coherence\n",
        "    - Grammatical accuracy\n",
        "    - Consistent tone and style\n",
        "    - Engagement and professionalism\n",
        "\n",
        "    Remove Markdown formatting including any *.\n",
        "    Make sure only the **best 3** hastags are used.\n",
        "\n",
        "    **Add** appropriate emojis in the post.\n",
        "\n",
        "    Provide the final version ready for posting.\n",
        "    Output **only** the final LinkedIn-ready post without any introductory or explanatory text.\n",
        "    **Do not** add links to any external resources.\n",
        "    \"\"\",\n",
        "    description = \"Produces final LinkedIn post with guardrails.\",\n",
        "    output_key = \"final_post\",\n",
        "    after_model_callback = final_draft_guardrail\n",
        ")"
      ],
      "metadata": {
        "id": "O-3lqnnexs7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!uv pip install \"crewai[tools]\" --prerelease=allow"
      ],
      "metadata": {
        "id": "yYAZU4Qp6lXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up DALL-E image creation tool from CrewAI\n",
        "\n",
        "from google.adk.tools.crewai_tool import CrewaiTool\n",
        "from crewai_tools import DallETool\n",
        "\n",
        "dalle_tool_instance = DallETool(model=\"dall-e-3\",\n",
        "                       size=\"1024x1024\",\n",
        "                       quality=\"hd\",\n",
        "                       n=1)\n",
        "\n",
        "adk_dalle_tool = CrewaiTool(\n",
        "    name = \"DALLE_Image_Creation_Tool\",\n",
        "    description=\"Generates images using DALLE.\",\n",
        "    tool=dalle_tool_instance,\n",
        ")"
      ],
      "metadata": {
        "id": "abB1fdvD6zt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up OpenAI API key\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "N-Au4jEB9JpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Image Generation Agent\n",
        "image_generation_agent = LlmAgent(\n",
        "    name = \"Image_Generation_Agent\",\n",
        "    model = GEMINI_MODEL,\n",
        "    instruction = \"\"\"\n",
        "    You are an Image Generation AI.\n",
        "    Generate an beautiful, minimalistic and attention grabbing image for the context provided in the session state with the key 'final_post'.\n",
        "    It should visually represent the key insights of the final LinkedIn post.\n",
        "    This image will be posted with this LinkedIn post.\n",
        "    **Please avoid** using any text in the image.\n",
        "    Return the URL of the infographic image in your response.\n",
        "    \"\"\",\n",
        "    description = \"Generates image using DALL-E.\",\n",
        "    tools = [adk_dalle_tool],\n",
        "    output_key = \"image_url\"\n",
        ")"
      ],
      "metadata": {
        "id": "ft72fFET718K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.adk.agents.sequential_agent import SequentialAgent\n",
        "\n",
        "linkedin_content_creation_pipeline = SequentialAgent(\n",
        "    name=\"LinkedIn_Content_Creation_Pipeline\",\n",
        "    sub_agents=[parallel_web_research_agent, writer_agent, seo_optimizer_agent, final_draft_writing_agent, image_generation_agent]\n",
        ")"
      ],
      "metadata": {
        "id": "vgBLMgluxwve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.adk.sessions import InMemorySessionService\n",
        "from google.adk.runners import Runner\n",
        "\n",
        "# Set up Session\n",
        "session_service = InMemorySessionService()\n",
        "session = session_service.create_session(app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID)\n",
        "\n",
        "# Set up Runner\n",
        "runner = Runner(agent=linkedin_content_creation_pipeline, app_name=APP_NAME, session_service=session_service)"
      ],
      "metadata": {
        "id": "6ev0BISMvZgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.genai import types\n",
        "\n",
        "def call_agent(query):\n",
        "    '''\n",
        "    Helper function to call the agent with a query.\n",
        "    '''\n",
        "    content = types.Content(role='user', parts=[types.Part(text=query)])\n",
        "    events = runner.run(user_id=USER_ID, session_id=SESSION_ID, new_message=content)\n",
        "\n",
        "    for event in events:\n",
        "        if event.is_final_response():\n",
        "            author = event.author\n",
        "            final_response = event.content.parts[0].text\n",
        "            print(f\"{author} Response:\\n{final_response}\\n\")"
      ],
      "metadata": {
        "id": "Pv_n0iHCvnBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "call_agent(\"how to master patience\")"
      ],
      "metadata": {
        "id": "bVOxa8D8vwsA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}